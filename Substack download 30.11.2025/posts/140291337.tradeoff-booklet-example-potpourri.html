<p>Since I have been thinking about &amp; writing about tradeoffs, I’m seeing them <em>everywhere</em>. “Oh, that’s a tradeoff. That’s a tradeoff.” I’m assuming you are interested in this kind of brain worm or you wouldn’t have read this far. As a demonstration, then, here are a handful of tradeoffs I’ve pattern matched on in the last month.</p><p>Reviewing from the booklet outline, each tradeoff has the following anatomy:</p><ul><li><p>Goal. You’d like some observable property of the system to change. For some reason, this usually is a cost that you’d like to reduce.</p></li><li><p>Control. To reduce towards some goal, you change an input to the system. This control has two extreme points &amp; lots of options in between.</p></li><li><p>Response curve. In response to the change in control, the system moves towards the goal.</p></li><li><p>Counter response curve. The system also responds by moving <em>away</em> from the goal (perverse universe, no?)</p></li></ul><p>This leads to the tradeoff. We want the goal, we change the control, we approach the goal, then we start moving away from the goal, then we either panic or we get on with analyzing the situation as a tradeoff.</p><h2>Examples</h2><p>One thing about Thinkies for me (including tradeoff thinking) is that once they are in my head, I can’t get them out.</p><h3>Measurement Precision</h3><p>I got thinking about this one when the whole “measuring developer productivity” kerfuffle blew up. I’ll write this up as a whole post, but the summary is:</p><ul><li><p>Goal: reduce waste</p></li><li><p>Control: precision of “productivity” measurement</p></li><li><p>From: none</p></li><li><p>To: per keystroke</p></li><li><p>Curve: wasted effort because you’re working unproductively</p></li><li><p>Counter curve: overhead of collection &amp; analysis</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/$s_!KIMR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!KIMR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 424w, https://substackcdn.com/image/fetch/$s_!KIMR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 848w, https://substackcdn.com/image/fetch/$s_!KIMR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 1272w, https://substackcdn.com/image/fetch/$s_!KIMR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic" width="1456" height="1094" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1094,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:180789,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/$s_!KIMR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 424w, https://substackcdn.com/image/fetch/$s_!KIMR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 848w, https://substackcdn.com/image/fetch/$s_!KIMR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 1272w, https://substackcdn.com/image/fetch/$s_!KIMR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F809f9eee-9cd3-40f7-90bc-1fd7c6502482.heic 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></button><button tabindex="0" type="button" class="pencraft pc-reset pencraft icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></button></div></div></div></a></figure></div><p>Lots more to say about how this picture is naive, but that’s the structure of the tradeoff.</p><h3>Clean Up Before/After</h3><p>This is the question of, when you write a test, do you clean up non-local state before executing the test?</p><p><code>setUp:<br>    eraseDatabase()</code></p><p><code>testWhatever:<br>    // all that test-y goodness</code></p><p>Or do you clean up after the test?</p><p><code>tearDown:<br>    eraseDatabase()</code></p><p><code>testWhatever:<br>    // all that test-y goodness</code></p><p>I decided this wasn’t actually a tradeoff, because there wasn’t a continuum of answers. There are two options, each of which has pros &amp; cons. (I’m biased towards clean-up-after, but I don’t mind having the debate.)</p><h3>Test In Production/Test In Staging</h3><p>How much feedback do you take from your production environment? How much do you expect to catch in a staging environment?</p><p>Goal: fewer production defects</p><p>Control: number &amp; accuracy of staging environments</p><p>From: nearly-perfect shadow environments</p><p>To: directly editing the production system</p><p>Curve: production defects that would have be caught</p><p>Counter-curve: cost of delay, cost of highly accurate staging, cost of relying on staging to catch errors (high-wire walkers without a net are safer), inevitable cost of shared resources (lots of stories about this)</p><p>The crux of this tradeoff is that folks think they can build a perfect staging environment &amp; they just can’t. You’re going to have to pay attention to prod, so count on it (&amp; sources of errors other ways).</p><h3>Number of PRs Per Deployment</h3><p>Batching PRs seems like a way to reduce the cost of deployment. Fewer deployments, fewer costs, right? Only up to a point.</p><p>Goal: reduce cost of deployment (my neck hairs are already standing up, since this is sub-system goal, progress on which could easily lead to degradation of the overall system)</p><p>Control: number of PRs per deployment</p><p>From: 1</p><p>To: thousands</p><p>Curve: overhead per deployment</p><p>Counter curve: disruption from failed deployments, whether rolled back or forward</p><p>At Facebook, the operations team noticed that around 100 PRs per deployment you started seeing sharply increased costs because PRs accidentally interfered with each other. They’d increase deployment frequency to reduce the number of PRs per deployment. Engineers would scream bloody murder. Things would settle down. Repeat 6 months later.</p><h3>Cost of Delay Vs Cost of Error</h3><p>This strikes me now as not really a fully-fledged tradeoff, but rather a category of error when working inside a tradeoff. Errors have obvious cost &amp; often an obvious cause. Delays tend to be invisible &amp; diffuse. We work to eliminate errors, even at the cost of enormous delays (blocking, synchronous code reviews being the classic example).</p><h3>Value of Collaboration Vs Value of Divide &amp; Conquer</h3><p>The Thinkie <a href="https://tidyfirst.substack.com/p/thinkie-match-the-pipes">Match The Pipes</a> is an example of this. Again, this is more a category of errors when working inside a tradeoff. It’s easy to see the potential gains from divide-and-conquer. 9 mothers, 1 month! It’s hard to see the cost of integration. After all, it happens after you’re “done”.</p><h2>Conclusion</h2><p>So there you go, a few tradeoffs, a few tradeoff-adjacent observations. When you think you see a tradeoff, I recommend that you actually draw the whole thing out. What are the goal, the control, the extremes of the control, the response &amp; counter-response curves? Switch the polarity of the goal (more about that later).</p><p>I often find that even when my tradeoff alarm has been activated, I’m not really in a tradeoff space. Or I may be in a tradeoff but I can’t articulate its dimensions. And this after hundreds or thousands of tradeoffs in several decades of working this way. You’ll catch on quicker than that. I believe in you. But draw it anyway.</p>