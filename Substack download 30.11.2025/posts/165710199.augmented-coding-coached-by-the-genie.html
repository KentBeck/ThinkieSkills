<p>When things improve, that’s great. When things improving increases the rate of improvement, that’s a revolution. I’m always on the lookout for a positive second derivative. Genies are there.</p><p>(Caveat: Genies are still subject to natural law. There’s a reinforcing loop driving improvement &amp; eventually an inhibiting loop preventing further improvement, an asymptote, a limit to how good the genie can get. But right now all we know is that the rocket is lit &amp; we’re hanging on by our fingernails &amp; we don’t know how much fuel is in the tanks.)</p><p><span class="mention-wrap" data-attrs="{&quot;name&quot;:&quot;Steve Yegge&quot;,&quot;id&quot;:132549450,&quot;type&quot;:&quot;user&quot;,&quot;url&quot;:null,&quot;photo_url&quot;:&quot;https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a431648-d32b-4105-8a3c-feef18443104_2316x3088.jpeg&quot;,&quot;uuid&quot;:&quot;ce86b807-4998-486a-a9be-c8a7fbfd20e6&quot;}" data-component-name="MentionToDOM"></span> &amp; Josh Cannon encouraged me to get in the habit of asking the genie whenever I have <em>any</em> question. Some of the answers are useful, some are not, but at this early stage I have no intuition <em>a priori</em> about which will be which.</p><p>I’m coming to a releasable state for a B+ Tree implementation in Rust &amp; Python (about which way more detail later). As the tension dissipated, I started wondering (as I always do), “Could I have done this better?” Hey! That’s a question! Ask the genie!!!</p><p>Here’s my prompt:</p><div class="pullquote"><p>We are working to make the human/genie (that's you, genie) collaboration work more smoothly. Look at the commit history &amp; advise me how the results could have come in less time by using your capabilities more efficiently.</p></div><p>The full text of the response is at the end of the post. Here is what I took away:</p><ul><li><p><strong>Batch similar refactors together</strong>—Instead of making separate commits for individual patterns, request comprehensive multi-file patches that transform all instances of a pattern (like Option combinators) across the entire codebase at once.</p></li><li><p><strong>Plan refactoring by pattern scope, not file-by-file</strong>—Define clear phases upfront (e.g., "Phase A: unify sibling-lookup logic") and provide the AI with a master checklist to systematically address each pattern type in atomic commits.</p></li><li><p><strong>Synchronize documentation and code changes</strong>—Bundle related doc updates with code refactors in single commits to prevent drift, and leverage AI's strength at comprehensive transformations rather than treating it like an incremental pair programmer.</p></li></ul><p>I’m not sure I fully believe this advice. Bigger leaps result in more chances to get trapped in the Complexity Tarpit. But it’s interesting to think about.</p><p>Another weakness of the response is that this wasn’t just refactoring. There was a bunch of new feature development (or there wouldn’t have been anything to refactor). Not sure how the genie missed this. I’ll go ask…</p><p>It was skimping on context. I asked it to summarize the whole 4 weeks. (More details in that other post.) It concluded by saying, with unwarranted confidence:</p><div class="pullquote"><p>Grouping commits into four major weekly scopes rather than dozens of micro‑commits would have produced a much clearer, easier‑to‑review history. Each scope could have been delivered as a single multi‑file patch (code + docs + tests), collapsing ~ 265 micro‑commits into four atomic commits.</p></div><p>There’s an interesting sport here—speed running augmented coding. How quickly can you get to a system fulfilling a (hidden) set of tests?</p><h2>Conclusion</h2><p>The big lesson for me is to use the genie to make my use of the genie more effective. I’m not used to this but it is slowly becoming a habit. Try it yourself in every situation you can imagine. If you have a question, ask the genie. Let us know how that goes.</p><h2>Appendix: Genie’s Full Response</h2><p>Here’s exactly what Codex said.</p><h3><strong>Lessons from a Refactoring Sprint: How to Collaborate More Efficiently with AI</strong></h3><p><em>A post-mortem on improving human-AI collaboration for large-scale code refactoring</em></p><div><hr></div><p>Recently, I completed a two-day refactoring sprint on a B+ tree implementation, working alongside an AI assistant. While we successfully cleaned up the codebase, the process revealed some important lessons about how to collaborate more efficiently with AI on large refactoring tasks.</p><h3><strong>What Actually Happened</strong></h3><p>Over June 5-6, we made steady progress refactoring our Rust codebase, but it happened in small, incremental steps. Here's what the git log looked like:</p><pre><code><code>2025-06-05 77349c0  refactor: move NodeRef tests from src/lib.rs to tests/bplus_tree.rs
2025-06-05 44066a4  refactor: unify get_mut with recursive pattern and add value overwrite test
2025-06-05 6ce3b4e  refactor: simplify branch sibling lookup with match patterns
2025-06-05 4f72b32  refactor: replace remove with recursive pattern following insert design
2025-06-05 ff302bc  docs: remove outdated Phase 4 section and delete plan.md
2025-06-05 7ebe179  refactor: improve code organization and formatting in remove operations
2025-06-05 bb2bf62  refactor: add polymorphic helpers for borrowing and merging operations
2025-06-05 c74bf7f  refactor: use Option combinator for linked list pointer update
2025-06-05 1fcb965  refactor: simplify nested if-let with Option combinator chain
2025-06-05 02690da  refactor: replace multiple if-let patterns with Option combinators
2025-06-06 40a81ee  docs: add concurrency control analysis for B+ trees</code></code></pre><p>Nine separate commits on June 5 alone, each tackling a different pattern or small improvement. While each change was valuable, the piecemeal approach created unnecessary overhead in review cycles and commit history.</p><h3><strong>How We Could Have Been More Efficient</strong></h3><p>Reflecting on this experience, I identified several strategies that would have dramatically reduced the time and effort required:</p><h4><strong>1. Bundle Similar Refactors Together</strong></h4><p>Instead of addressing patterns one at a time, I could have requested batch operations:</p><blockquote><p>"Please refactor all the <code>if let Some(...) { ... } else { return false; }</code> patterns into concise Option combinator style across the entire codebase."</p></blockquote><p>The AI could then:</p><ul><li><p>Search the entire codebase for matching patterns using tools like <code>ripgrep</code></p></li><li><p>Apply a single multi-file patch transforming all instances at once</p></li><li><p>Create one atomic commit covering the entire pattern replacement</p></li></ul><h4><strong>2. Use Code Search + Multi-File Patching</strong></h4><p>AI assistants excel at regex-based transformations and can handle multiple files simultaneously. Rather than manual, iterative edits, they can write comprehensive patches that fold multiple small refactors into one clean, atomic change.</p><h4><strong>3. Synchronize Documentation and Code Changes</strong></h4><p>We made separate commits for documentation updates and code changes, allowing them to drift apart temporarily. A better approach would be to request bundled changes:</p><blockquote><p>"Update the refactoring plan (delete Phase 4) and apply all refactors for phases 2-3 in one patch."</p></blockquote><p>This keeps documentation and implementation perfectly synchronized.</p><h4><strong>4. Define Refactor Scopes Up-Front</strong></h4><p>At the beginning of a refactoring sprint, create a clear checklist of patterns to address:</p><ul><li><p>Recursive pattern unification</p></li><li><p>Branch sibling lookup simplification</p></li><li><p>Option combinator adoption</p></li><li><p>Test organization improvements</p></li></ul><p>Hand this list to your AI collaborator, and they can systematically map the entire codebase against these patterns, generating comprehensive patches for each scope.</p><h4><strong>5. Use Interactive Planning</strong></h4><p>Leverage AI for discovery and planning: "Show me every remaining <code>match foo { Some... } else { return false }</code> pattern." This prevents discovering refactoring opportunities piecemeal and committing them ad hoc.</p><h3><strong>Recommended Workflow for Future Sprints</strong></h3><p>Based on these insights, here's the workflow I'll use going forward:</p><p><strong>Phase work by pattern, not by file.</strong> Each phase should address one type of refactoring across the entire codebase:</p><ul><li><p>Phase A: Unify all sibling-lookup logic → one commit</p></li><li><p>Phase B: Batch-apply Option-combinator refactor → one commit</p></li><li><p>Phase C: Reorganize test structure → one commit</p></li></ul><p><strong>Maintain a master checklist</strong> that gets updated in real-time as the AI marks each item complete.</p><p><strong>Request multi-file transformations</strong> that can span dozens of locations safely using regex or AST-based refactoring tools.</p><p><strong>Group documentation and code changes</strong> together so they never fall out of sync.</p><h3><strong>The Bottom Line</strong></h3><p>By front-loading clear planning and requesting batch operations, we could have collapsed nine incremental commits into two or three well-scoped, atomic commits. This would have saved review time, reduced overhead, and kept the repository history much cleaner.</p><p>The key insight is that AI assistants are particularly good at systematic, comprehensive transformations when given clear scope and direction. Playing to these strengths—rather than treating them like human pair programmers who work incrementally—unlocks much more efficient collaboration.</p><div><hr></div><p><em>Have you experimented with AI-assisted refactoring? I'd love to hear about your experiences and any strategies you've discovered for effective human-AI collaboration in the comments.</em></p>